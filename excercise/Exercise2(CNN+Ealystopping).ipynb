{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise2(CNN+Ealystopping).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwwoDTitymo44rD3pYiy8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebenvy/tdc/blob/master/excercise/Exercise2(CNN%2BEalystopping).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uJWKui2KSdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "In the course you learned how to do classification using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
        "\n",
        "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
        "\n",
        "Some notes:\n",
        "\n",
        "1. It should succeed in less than 10 epochs, so it is okay to change epochs to 10, but nothing larger\n",
        "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
        "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
        "I've started the code for you below -- how would you finish it?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNvgdtcNLhjq",
        "colab_type": "text"
      },
      "source": [
        "Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqDC0O5HKZkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " YOUR CODE SHOULD START HERE\n",
        "# YOUR CODE SHOULD END HERE\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "# YOUR CODE SHOULD START HERE\n",
        "\n",
        "# YOUR CODE SHOULD END HERE\n",
        "model = tf.keras.models.Sequential([\n",
        "# YOUR CODE SHOULD START HERE\n",
        "    \n",
        "# YOUR CODE SHOULD END HERE\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# YOUR CODE SHOULD START HERE\n",
        "# YOUR CODE SHOULD END HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXj3Qk7-Lktl",
        "colab_type": "text"
      },
      "source": [
        "Answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boO7j1pULnF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "9f38e615-a1c9-442e-bd51-32045285a82f"
      },
      "source": [
        "# YOUR CODE SHOULD END HERE\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "# YOUR CODE SHOULD START HERE\n",
        "x_train = x_train.reshape(x_train.shape+(1,))\n",
        "x_test = x_test.reshape(x_test.shape+(1,))\n",
        "x_train= x_train/255.0\n",
        "x_test= x_test/255.0\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "# YOUR CODE SHOULD END HERE\n",
        "model = tf.keras.models.Sequential([\n",
        "# YOUR CODE SHOULD START HERE\n",
        "tf.keras.layers.Conv2D(32,(3,3),input_shape=x_train.shape[1:],activation='relu'),\n",
        "tf.keras.layers.MaxPool2D((3,3),2),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(10,activation='softmax'),\n",
        "# YOUR CODE SHOULD END HERE\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# YOUR CODE SHOULD START HERE\n",
        "model.fit(x_train,y_train,epochs=10,callbacks=[callbacks])\n",
        "model.evaluate(x_test,y_test)\n",
        "# YOUR CODE SHOULD END HERE"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.2164 - accuracy: 0.9372\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0777 - accuracy: 0.9771\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0603 - accuracy: 0.9818\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0489 - accuracy: 0.9852\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0426 - accuracy: 0.9871\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0362 - accuracy: 0.9891\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9903\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0318 - accuracy: 0.9903\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04780701547861099, 0.9861000180244446]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZtHamoyoOPE",
        "colab_type": "text"
      },
      "source": [
        "tensorflow callback 사용\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback\n",
        "\n",
        "https://hwiyong.tistory.com/120"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijHMoChILsCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_train_batch_begin(self, batch, logs=None):\n",
        "    print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_test_batch_begin(self, batch, logs=None):\n",
        "    print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "\n",
        "  def on_test_batch_end(self, batch, logs=None):\n",
        "    print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}